# ANSD_letter_recognition

## Проект выполнявшийся на курсе Анализ Неструктурированных данных на факультете ВМК МГУ, 5 семестр 2024 год

### Описание

Я решил строить сеть для распознования 5 различных букв латинского алфавита: N, K, P, R, Z.

Для этого был создан датасет `letters_dataset`, в котором содержится по 10 вручную созданных примеров на каждую букву. Файлы имеют разрешение 32 на 32, и формат `.png`, создать свои примеры (*бесплатно*) можно на сайте [piskel](https://www.piskelapp.com/p/create/sprite), главное выставить соответствующие настройки.

### Структура репозитория

1. Папка `letters_dataset`, – здесь содержится по 10 вручную созданных примеров на каждую букву.
2. Датасет `augmented_dataset` содержит дополнительную аугментацию букв, содержащихся в `letters_dataset`, она заключается в сдвиге данных по картинке и рисовании букв различными цветами.
3. В папку `models` сохранялись рабочие модели для последующего их использования (чтобы не тратить время на обучение при повторных запусках ноутбука)
4. В папке `test_inputs` лежат 10 тестовых примеров различных букв (созданных отдельно, они не встречаются в тренировочном датасете), сюда же необходимо добавлять новые примеры при желании дополнительно протестировать модель.
5. В папке `augmented_input_K` содержится 15 примеров аугментированных букв K, которая для сети является наиболее проблемной из-за ее схожести с буквой R, в конце ноутбука есть возможность проверить на нем работу нейросети и убедится, что ошибки классификации возникают.
6. Ноутбук `data_preparation.ipynb` содержит загрузку данных и их визуализацию плюс тестовый запуск модели
7. Ноутбук `model_creation.ipynb` содержит описание построенной модели а также ее обучение и тестирование

### Использованные библиотеки

* `pillow (PIL)`, а конкретно Image, для конвертации `.png` файлов в формат `numpy`-массивов, а также для вывода их на экран
* `numpy` - для работы с массивами пикселей, представляющих картинки
* `pandas` - для ковертации массивов данных в удобный формат DataFrame, и последующего его использования для разделения данных на тренировочную и обучающие выборки
* `tensorflow`, а конкретно keras, для построения трехслойной нейронной сети, осуществляющей обработку изображений
* `os` - для чтения файлов
* `matplotlib.pyplot` - для вывода рисунков символов на экран
* `train_test_split` из `sklearn` для удобного (случайного) разбиения данных на обучающую и тестовую выборки
